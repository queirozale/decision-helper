{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebc1fec-1e67-4176-8e8e-4a2980c0235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import all_estimators\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4160d333-1ccd-4c4d-857d-5ae1c1e323bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abdd2ab-720e-42f6-93c6-1b667d427126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decomposition import TimeSeriesDecomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca69803-ef0b-4d1b-a6c8-fe46f6795350",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/raw/pinheiro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d258e0cb-7dbb-42b1-bc1e-0bbe8c39df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(os.path.join(DATA_PATH, 'sales.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffa6ce6-b7e6-4208-837d-8574c14d7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales.groupby(['date', 'product_code'])['unit_sales'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748c05cd-4278-49e0-b7ca-b547ca63303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales[df_sales['date'] < '2019-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e8672d-f111-465c-9a13-bdf3ce298444",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_avg_sales = df_sales.groupby(['product_code'])['unit_sales'].mean().reset_index().sort_values(by='unit_sales', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf9670e-ef48-49da-bf0a-b487c21e05cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>104649</td>\n",
       "      <td>938.768914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>58008</td>\n",
       "      <td>393.344220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>60504</td>\n",
       "      <td>182.699131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>52060</td>\n",
       "      <td>177.045465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1386</td>\n",
       "      <td>153.792687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>126523</td>\n",
       "      <td>2.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1292</td>\n",
       "      <td>2.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>88073</td>\n",
       "      <td>0.668233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>131935</td>\n",
       "      <td>0.158365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>53037</td>\n",
       "      <td>0.070019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_code  unit_sales\n",
       "192        104649  938.768914\n",
       "126         58008  393.344220\n",
       "140         60504  182.699131\n",
       "110         52060  177.045465\n",
       "10           1386  153.792687\n",
       "..            ...         ...\n",
       "228        126523    2.357143\n",
       "6            1292    2.276400\n",
       "177         88073    0.668233\n",
       "240        131935    0.158365\n",
       "114         53037    0.070019\n",
       "\n",
       "[242 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_avg_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0dfb45-766b-4297-b7b8-2e3b7bc61a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.read_csv(os.path.join(DATA_PATH, 'products.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "930abbf4-ee0d-4bf4-972e-d147ebf38b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104649</td>\n",
       "      <td>938.768914</td>\n",
       "      <td>CERV.SKOL 300ML RETORNAVEL (LIQUIDO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58008</td>\n",
       "      <td>393.344220</td>\n",
       "      <td>LEITE PO ITAMBE INTEGR.200G SCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60504</td>\n",
       "      <td>182.699131</td>\n",
       "      <td>ACHOC.LIQ.NESCAU PRONTINHO 200ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52060</td>\n",
       "      <td>177.045465</td>\n",
       "      <td>CERV.SCHIN.350ML PILSEN LT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386</td>\n",
       "      <td>153.792687</td>\n",
       "      <td>BATATA INGLESA KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>126523</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>GOMA MASC.TRIDENT SAB.18S MENTA 30,6G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1292</td>\n",
       "      <td>2.276400</td>\n",
       "      <td>CHESTER PERDIGAO CONG.KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>88073</td>\n",
       "      <td>0.668233</td>\n",
       "      <td>LEITE L.VIDA BETANIA DESN.UHT VITAM.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>131935</td>\n",
       "      <td>0.158365</td>\n",
       "      <td>BEB.LACT.ITAMBE GOODY MORANGO BDJ 540G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>53037</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>CREME DE LEITE PARMALAT 200G TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_code  unit_sales                             description\n",
       "0          104649  938.768914    CERV.SKOL 300ML RETORNAVEL (LIQUIDO)\n",
       "1           58008  393.344220         LEITE PO ITAMBE INTEGR.200G SCH\n",
       "2           60504  182.699131        ACHOC.LIQ.NESCAU PRONTINHO 200ML\n",
       "3           52060  177.045465              CERV.SCHIN.350ML PILSEN LT\n",
       "4            1386  153.792687                       BATATA INGLESA KG\n",
       "..            ...         ...                                     ...\n",
       "237        126523    2.357143   GOMA MASC.TRIDENT SAB.18S MENTA 30,6G\n",
       "238          1292    2.276400                CHESTER PERDIGAO CONG.KG\n",
       "239         88073    0.668233  LEITE L.VIDA BETANIA DESN.UHT VITAM.1L\n",
       "240        131935    0.158365  BEB.LACT.ITAMBE GOODY MORANGO BDJ 540G\n",
       "241         53037    0.070019         CREME DE LEITE PARMALAT 200G TP\n",
       "\n",
       "[242 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_avg_sales.merge(df_product[['product_code', 'description']], on='product_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea918517-3e83-40ff-9fcd-1156a039e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sales[df_sales['product_code'] == 104649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834f81b7-a7e8-449a-9d55-aeace1d7a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'unit_sales': 'y'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01be1382-8d73-4e7d-a687-67d9e29001d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_decomposer = TimeSeriesDecomposer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba2a53e3-cea4-4f11-a7ed-a59e037fc1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_code</th>\n",
       "      <th>y</th>\n",
       "      <th>ma_7</th>\n",
       "      <th>trend</th>\n",
       "      <th>detrend_y</th>\n",
       "      <th>seasonality</th>\n",
       "      <th>remainder</th>\n",
       "      <th>at</th>\n",
       "      <th>st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>104649</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>104649</td>\n",
       "      <td>219.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>104649</td>\n",
       "      <td>663.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>104649</td>\n",
       "      <td>428.250</td>\n",
       "      <td>776.535714</td>\n",
       "      <td>776.535714</td>\n",
       "      <td>-348.285714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>104649</td>\n",
       "      <td>1201.375</td>\n",
       "      <td>879.017857</td>\n",
       "      <td>879.017857</td>\n",
       "      <td>322.357143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256470</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>104649</td>\n",
       "      <td>1091.250</td>\n",
       "      <td>1096.214286</td>\n",
       "      <td>1096.214286</td>\n",
       "      <td>-4.964286</td>\n",
       "      <td>27.377551</td>\n",
       "      <td>-32.341837</td>\n",
       "      <td>1063.872449</td>\n",
       "      <td>27.377551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256712</th>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>104649</td>\n",
       "      <td>897.125</td>\n",
       "      <td>942.875000</td>\n",
       "      <td>942.875000</td>\n",
       "      <td>-45.750000</td>\n",
       "      <td>79.181122</td>\n",
       "      <td>-124.931122</td>\n",
       "      <td>817.943878</td>\n",
       "      <td>79.181122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256954</th>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>104649</td>\n",
       "      <td>944.625</td>\n",
       "      <td>1037.458333</td>\n",
       "      <td>1037.458333</td>\n",
       "      <td>-92.833333</td>\n",
       "      <td>14.671769</td>\n",
       "      <td>-107.505102</td>\n",
       "      <td>929.953231</td>\n",
       "      <td>14.671769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257196</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>104649</td>\n",
       "      <td>1340.375</td>\n",
       "      <td>1133.200000</td>\n",
       "      <td>1133.200000</td>\n",
       "      <td>207.175000</td>\n",
       "      <td>35.275850</td>\n",
       "      <td>171.899150</td>\n",
       "      <td>1305.099150</td>\n",
       "      <td>35.275850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257438</th>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>104649</td>\n",
       "      <td>1392.625</td>\n",
       "      <td>1143.687500</td>\n",
       "      <td>1143.687500</td>\n",
       "      <td>248.937500</td>\n",
       "      <td>-130.365731</td>\n",
       "      <td>379.303231</td>\n",
       "      <td>1522.990731</td>\n",
       "      <td>-130.365731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1064 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  product_code         y         ma_7        trend  \\\n",
       "192     2017-01-01        104649     0.000          NaN          NaN   \n",
       "434     2017-01-02        104649   219.250          NaN          NaN   \n",
       "676     2017-01-03        104649   663.750          NaN          NaN   \n",
       "918     2017-01-04        104649   428.250   776.535714   776.535714   \n",
       "1160    2017-01-05        104649  1201.375   879.017857   879.017857   \n",
       "...            ...           ...       ...          ...          ...   \n",
       "256470  2019-11-26        104649  1091.250  1096.214286  1096.214286   \n",
       "256712  2019-11-27        104649   897.125   942.875000   942.875000   \n",
       "256954  2019-11-28        104649   944.625  1037.458333  1037.458333   \n",
       "257196  2019-11-29        104649  1340.375  1133.200000  1133.200000   \n",
       "257438  2019-11-30        104649  1392.625  1143.687500  1143.687500   \n",
       "\n",
       "         detrend_y  seasonality   remainder           at          st  \n",
       "192            NaN          NaN         NaN          NaN         NaN  \n",
       "434            NaN          NaN         NaN          NaN         NaN  \n",
       "676            NaN          NaN         NaN          NaN         NaN  \n",
       "918    -348.285714          NaN         NaN          NaN         NaN  \n",
       "1160    322.357143          NaN         NaN          NaN         NaN  \n",
       "...            ...          ...         ...          ...         ...  \n",
       "256470   -4.964286    27.377551  -32.341837  1063.872449   27.377551  \n",
       "256712  -45.750000    79.181122 -124.931122   817.943878   79.181122  \n",
       "256954  -92.833333    14.671769 -107.505102   929.953231   14.671769  \n",
       "257196  207.175000    35.275850  171.899150  1305.099150   35.275850  \n",
       "257438  248.937500  -130.365731  379.303231  1522.990731 -130.365731  \n",
       "\n",
       "[1064 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_decomposer.decompose(\n",
    "    m=7, season=7, decomposition_type='classical', classical_method='additive'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf3c860b-7cc3-41d4-8bdc-86b0f3b62899",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime(2019, 11, 30, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a2e55f-71b7-4792-b09d-5bfb21538fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b60fd57b-8b41-4277-886f-9d8bfed9c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08110bb6-dfd6-4377-92b1-65cfa3820e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123c505a-15da-43ce-9125-1f609ce467b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ma(df, m):\n",
    "    k = int((m-1)/2)\n",
    "    ma = []\n",
    "    for i in range(len(df)):\n",
    "        i_start = i - k\n",
    "        i_end = i + k + 1\n",
    "        if i_start < 0:\n",
    "            ma.append(np.nan)\n",
    "        else:\n",
    "            ma.append(df.iloc[i_start:i_end]['y'].mean())\n",
    "            \n",
    "    df[f'ma_{m}'] = ma\n",
    "    return df\n",
    "\n",
    "\n",
    "def decompose_ts(df, m, season):\n",
    "    df = compute_ma(df, m)\n",
    "    df['trend'] = df['ma_7']\n",
    "    df['detrend_y'] = df['y'] - df['trend']\n",
    "    df['seasonality'] = df['detrend_y'].rolling(window=season).mean()\n",
    "    df['remainder'] = df['y'] - df['trend'] - df['seasonality']\n",
    "    df['at'] = df['trend'] + df['remainder']\n",
    "    df['st'] = df['seasonality']\n",
    "    \n",
    "    return df\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, df, start_date):\n",
    "        self.df = df\n",
    "        self.date_list = df[df['date'] >= start_date]['date'].tolist()\n",
    "        self.features = {'date': self.date_list}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_previous_y(df, n, by_weekday, **kwargs):\n",
    "        if by_weekday:\n",
    "            date = kwargs.get('date')\n",
    "            wd = date.weekday()\n",
    "            df_weekday = df[df['weekday'] == wd]\n",
    "            return df_weekday.iloc[-n:].sort_values(by='date', ascending=False)['y'].T.values\n",
    "        else:\n",
    "            return df.iloc[-n:].sort_values(by='date', ascending=False)['y'].T.values   \n",
    "\n",
    "    @staticmethod\n",
    "    def get_wom(date):\n",
    "        wom = math.ceil(date.day/7)\n",
    "        if wom > 4:\n",
    "            return 4\n",
    "        else:\n",
    "            return wom\n",
    " \n",
    "    def get_autoregressive_features(self, n_days, n_weeks):\n",
    "        cols1 = [f'yt-{k}' for k in range(1, n_days+1)]\n",
    "        cols2 = [f'yt-{k*7}' for k in range(1, n_weeks+1)]\n",
    "        cols = cols1 + cols2\n",
    "        autoregressive_data = {}\n",
    "        for date in self.date_list:\n",
    "            df_truncate = self.df[self.df['date'] < date].sort_values(by='date')\n",
    "            values_daily = self.get_previous_y(df_truncate, n_days, False)\n",
    "            values_weekly = self.get_previous_y(df_truncate, n_weeks, True, date=date)\n",
    "            values = np.concatenate((values_daily, values_weekly))\n",
    "            autoregressive_data[date] = values\n",
    "            \n",
    "        autoregressive_features = pd.DataFrame(autoregressive_data.values(), columns=cols)\n",
    "        self.features['autoregressive'] = autoregressive_features\n",
    "\n",
    "        \n",
    "    def get_categorical_features(self):\n",
    "        df_date = pd.DataFrame({'date': self.date_list})\n",
    "        df_date = df_date.merge(self.df, on='date')[['date', 'weekday']]\n",
    "        df_date['wom'] = df_date['date'].apply(lambda x: self.get_wom(x))\n",
    "        df_date['month'] = pd.DatetimeIndex(df_date['date']).month\n",
    "        df_date = df_date[df_date.columns[1:]]\n",
    "        \n",
    "        features = df_date.columns\n",
    "        categorical_features = pd.DataFrame()\n",
    "        for feature in features:\n",
    "            df_dummy = pd.get_dummies(df_date[feature])\n",
    "            df_dummy = df_dummy.rename(columns={\n",
    "                col: feature + '_' + str(col) for col in df_dummy.columns\n",
    "            })\n",
    "            categorical_features = pd.concat([categorical_features, df_dummy], axis=1)\n",
    "\n",
    "        self.features['categorical'] = categorical_features\n",
    "        \n",
    "    def extract(self, n_days, n_weeks):\n",
    "        self.get_autoregressive_features(n_days, n_weeks)\n",
    "        self.get_categorical_features()\n",
    "        \n",
    "\n",
    "def get_samples(features, df_, train_size):\n",
    "    sample_keys = [\n",
    "        ('autoregressive', 'at'),\n",
    "        ('categorical', 'st')\n",
    "    ]\n",
    "    \n",
    "    samples = {}\n",
    "    for sample_key in sample_keys:\n",
    "        feature_name, y_true_name = sample_key\n",
    "        feature_samples = {}\n",
    "        data = {\n",
    "            'train': {\n",
    "                'X': features[feature_name][:train_size],\n",
    "                'y': df_[[y_true_name]][:train_size]\n",
    "            },\n",
    "            'test': {\n",
    "                'X': features[feature_name][train_size:],\n",
    "                'y': df_[[y_true_name]][train_size:]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for set_ in data.keys():\n",
    "            feature_samples[set_] = {}\n",
    "            for k, vec in data[set_].items():\n",
    "                scaler = MinMaxScaler()\n",
    "                vec_scaled = scaler.fit_transform(vec)\n",
    "                feature_samples[set_][k] = {\n",
    "                    'data': vec_scaled,\n",
    "                    'scaler': scaler\n",
    "                }\n",
    "\n",
    "        samples[feature_name] = feature_samples\n",
    "        \n",
    "    return samples\n",
    "\n",
    "def eval_model(model, samples):\n",
    "    result = {}\n",
    "    for feature_name, feature_samples in samples.items():\n",
    "        train_data = feature_samples['train']\n",
    "        X_train, y_train = train_data['X']['data'], train_data['y']['data']\n",
    "\n",
    "        test_data = feature_samples['test']\n",
    "        X_test, y_test = test_data['X']['data'], test_data['y']['data']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        train_scaler = train_data['y']['scaler']\n",
    "        test_scaler = test_data['y']['scaler']\n",
    "\n",
    "        y_true_train = train_scaler.inverse_transform(y_train)\n",
    "        y_true_test = train_scaler.inverse_transform(y_test)\n",
    "\n",
    "        y_pred_train = train_scaler.inverse_transform(y_pred_train.reshape(-1, 1))\n",
    "        y_pred_test = train_scaler.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "\n",
    "        result[feature_name] = {\n",
    "            'train': {\n",
    "                'true': y_true_train,\n",
    "                'pred': y_pred_train\n",
    "            },\n",
    "            'test': {\n",
    "                'true': y_true_test,\n",
    "                'pred': y_pred_test\n",
    "            }\n",
    "        }\n",
    "\n",
    "    y_true_train = result['autoregressive']['train']['true'] + result['categorical']['train']['true']\n",
    "    y_pred_train = result['autoregressive']['train']['pred'] + result['categorical']['train']['pred']\n",
    "\n",
    "    y_true_test = result['autoregressive']['test']['true'] + result['categorical']['test']['true']\n",
    "    y_pred_test = result['autoregressive']['test']['pred'] + result['categorical']['test']['pred']\n",
    "\n",
    "    results_metrics = {\n",
    "        'mae/avg': {\n",
    "            'train': mean_absolute_error(y_true_train, y_pred_train)/np.mean(y_true_train),\n",
    "            'test': mean_absolute_error(y_true_test, y_pred_test)/np.mean(y_true_test)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e273833-d78b-4375-8292-34afa84477c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in MODEL_DICT.values():\n",
    "#     print(eval_model(model, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82500188-e737-4806-a513-72d8f805c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[16, 8])\n",
    "# plt.plot(y_true_train[-100:], label='y_true')\n",
    "# plt.plot(y_pred_train[-100:], label='y_pred')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f356c05-3dbb-44c1-b812-14ccbbb30a2f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e75a96-5a11-4f2e-afa1-7fbe44348b95",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "213ec2e8-9859-4013-bf3e-4ee0d8f26e3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "--------------\n",
      "MultiOutputRegressor\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "--------------\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "--------------\n",
      "RegressorChain\n",
      "__init__() missing 1 required positional argument: 'base_estimator'\n",
      "--------------\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "--------------\n",
      "StackingRegressor\n",
      "__init__() missing 1 required positional argument: 'estimators'\n",
      "--------------\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "--------------\n",
      "VotingRegressor\n",
      "__init__() missing 1 required positional argument: 'estimators'\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "estimators = all_estimators(type_filter='regressor')\n",
    "\n",
    "all_regs = {}\n",
    "for name, RegressorClass in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        reg = RegressorClass()\n",
    "        all_regs[name] = reg\n",
    "    except Exception as e:\n",
    "        print('--------------')\n",
    "        print(name)\n",
    "        print(e)\n",
    "        print('--------------')\n",
    "        \n",
    "        \n",
    "performances = {}\n",
    "for name, model in all_regs.items():\n",
    "    try:\n",
    "        r = eval_model(model, samples)\n",
    "        test_performance = r['mae/avg']['test']\n",
    "        performances[name] = test_performance\n",
    "    except Exception as e:\n",
    "        print('--------------')\n",
    "        print(name)\n",
    "        print(e)\n",
    "        print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0264857-b19b-466d-b135-c6d4ce6178a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e0ae55-9d42-446c-8866-ee5d4fb32752",
   "metadata": {},
   "source": [
    "## Analyse difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99c015c3-3b51-4367-a7af-342b5b70a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 242/242 [00:32<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "trends = []\n",
    "seasonalities = []\n",
    "remainders = []\n",
    "baseline_values = []\n",
    "\n",
    "for product_code in tqdm(df_sales['product_code'].unique(), bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}'):\n",
    "    try:\n",
    "        df = df_sales[df_sales['product_code'] == product_code]\n",
    "\n",
    "        df.rename(columns={\n",
    "            'unit_sales': 'y'\n",
    "        }, inplace=True)\n",
    "\n",
    "        df['date']= pd.to_datetime(df['date'])\n",
    "        df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "        df['baseline'] = df['y'].rolling(window=7).mean()\n",
    "\n",
    "        df = decompose_ts(df, 7, 7)\n",
    "        start_date = datetime(2018, 1, 1)\n",
    "\n",
    "        date_list = df[df['date'] >= start_date]['date'].tolist()\n",
    "\n",
    "        train_ratio = 0.8\n",
    "        df_ = df[df['date'].isin(date_list)]\n",
    "        train_size = int(train_ratio * len(df_))\n",
    "\n",
    "        y_pred_baseline = df_['baseline'].values.reshape(-1, 1)\n",
    "        y_true = df_['y'].values.reshape(-1, 1)\n",
    "        baseline_value = mean_absolute_error(y_true, y_pred_baseline)/np.mean(y_true)\n",
    "\n",
    "        a = df[['trend', 'seasonality', 'remainder']].mean()\n",
    "        trends.append(a.trend)\n",
    "        seasonalities.append(a.seasonality)\n",
    "        remainders.append(a.remainder)\n",
    "        baseline_values.append(baseline_value)\n",
    "        \n",
    "    except:\n",
    "        print(f\"Error on product {product_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3cd6c34-8075-4f73-a3f4-edb5f806a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({\n",
    "    'product_code': df_sales['product_code'].unique(),\n",
    "    'trend': trends,\n",
    "    'seasonality': seasonalities,\n",
    "    'remainder': remainders,\n",
    "    'baseline_value': baseline_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6275157f-e934-4c6a-97eb-ee8d249c4406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>trend</th>\n",
       "      <th>seasonality</th>\n",
       "      <th>remainder</th>\n",
       "      <th>baseline_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3017</td>\n",
       "      <td>28.654651</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.079811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3260</td>\n",
       "      <td>9.010249</td>\n",
       "      <td>-0.001131</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.104733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1655</td>\n",
       "      <td>76.412537</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>-0.009316</td>\n",
       "      <td>0.107896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17183</td>\n",
       "      <td>67.763284</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.126692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10315</td>\n",
       "      <td>59.836242</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.127451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4121</td>\n",
       "      <td>4.577361</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>1.013166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5490</td>\n",
       "      <td>4.783399</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>1.037258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>57729</td>\n",
       "      <td>34.194931</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>1.041150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>58556</td>\n",
       "      <td>30.722343</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.004515</td>\n",
       "      <td>1.117394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>50979</td>\n",
       "      <td>49.728607</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>0.331315</td>\n",
       "      <td>1.167820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_code      trend  seasonality  remainder  baseline_value\n",
       "54           3017  28.654651    -0.001083   0.005092        0.079811\n",
       "55           3260   9.010249    -0.001131   0.001437        0.104733\n",
       "43           1655  76.412537     0.004289  -0.009316        0.107896\n",
       "96          17183  67.763284     0.003438   0.003226        0.126692\n",
       "93          10315  59.836242     0.002214   0.002642        0.127451\n",
       "..            ...        ...          ...        ...             ...\n",
       "66           4121   4.577361    -0.000354   0.000541        1.013166\n",
       "70           5490   4.783399     0.001585  -0.009259        1.037258\n",
       "122         57729  34.194931    -0.003339   0.006910        1.041150\n",
       "134         58556  30.722343     0.000813  -0.004515        1.117394\n",
       "105         50979  49.728607    -0.025999   0.331315        1.167820\n",
       "\n",
       "[242 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by='baseline_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "029a15d9-3b5a-401b-966c-e05e091317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "799f9c48-ede5-4fd3-8ecb-62245e9e6d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09003615506586217"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, _ = pearsonr(table['trend'], table['baseline_value'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c28fc94c-4ddd-4b1c-a95c-3b2e7bbafb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1697842451872687"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, _ = pearsonr(table['seasonality'], table['baseline_value'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d65e0b4-b92c-4c26-8676-ce5afc21002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18814399845484883"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr, _ = pearsonr(table['remainder'], table['baseline_value'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9756f-2418-42a9-835d-36543eb73081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
